<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Collaborative Adaptive Filters | Beth Jelfs</title> <meta name="author" content="Beth Jelfs"> <meta name="description" content="Convex combinations of adaptive filters"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?581358d64999829ebdbc91ba41a3b40b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://beteje.github.io/research/hybridfilters/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://beteje.github.io/"><span class="font-weight-bold">BethÂ </span>Jelfs</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News</a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">Research<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Collaborative Adaptive Filters</h1> <p class="post-description">Convex combinations of adaptive filters</p> </header> <article> <div class="row align-items-center"> <div class="col-sm-5 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/Nature-480.webp 480w, /assets/img/Nature-800.webp 800w, /assets/img/Nature-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/Nature.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Nature of signals" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">The majority of real world signals are represented by the areas marked '?'</figcaption> </figure> </div> <div class="col-sm-7 mt-3 mt-md-0">Signal modality characterisation allows us to understand more about the nature of the signals we are investigating. While some signal characteristics are well defined many signals do not fall neatly into these categories.</div> </div> <p>By using adaptive filters in a prediction configuration we can compare the output of filters designed for different inputs. This allows us to determine which algorithm has the best prediction of the signal.</p> <p>This solution is simple but the algorithms do not co-operate, to create an online signal modality characterisation solution with synergy between the filters the filters feed into a mixing algorithm which is also adaptive.</p> <div class="row align-items-center justify-content-center"> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/PredConf-480.webp 480w, /assets/img/PredConf-800.webp 800w, /assets/img/PredConf-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/PredConf.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Prediction configuration" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Adaptive filter prediction configuration.</figcaption> </figure> </div> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/Convex-480.webp 480w, /assets/img/Convex-800.webp 800w, /assets/img/Convex-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/Convex.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Convex combination" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Convex combination.</figcaption> </figure> </div> </div> <p>Using a convex combination of the filters guarantees the existence and uniqueness of a solution. The convex mixing parameter is adapted using a gradient descent update:</p> \[\begin{align*} \lambda(k+1) =&amp; \lambda(k) - \mu_\lambda\nabla_\lambda E(k)_{|\lambda=\lambda(k)}\\ =&amp; \lambda(k) - \frac{\mu_\lambda}{2}\frac{\partial e^2(k)}{\partial\lambda(k)}\\ =&amp; \lambda(k) + \mu_\lambda e(k)\big(y_1(k) - y_2(k)\big) \end{align*}\] <ul> <li>This solution can provide improved performance over the individual constituent filters;</li> <li>The mixing algorithm can give an indication of which filter is currently responding to the input signal most effectively;</li> <li>By appropriate selection of the algorithms the mixing algorithm can adapt according to fundamental properties of the input signal.</li> </ul> <div class="row align-items-center justify-content-center"> <div class="col-sm-5 mb-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/HybridFilter-480.webp 480w, /assets/img/HybridFilter-800.webp 800w, /assets/img/HybridFilter-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/HybridFilter.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Generic hybrid filter" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">General hybrid filter structure.</figcaption> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/PerfLinearHybrid-480.webp 480w, /assets/img/PerfLinearHybrid-800.webp 800w, /assets/img/PerfLinearHybrid-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/PerfLinearHybrid.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Performance of linear hybrid filter" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Example of the performance of a hybrid filter combining the LMS and GNGD algorithms.</figcaption> </figure> </div> </div> <p>By tracking the mixing parameter rather than the performance of the filter we can see which of the subfilters is being favoured by the hybrid filter. We can also combine several hybrid filters to gain a more complete picture of the nature of the signal under investigation.</p> <div class="row align-items-center"> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/CompLinNonlin-480.webp 480w, /assets/img/CompLinNonlin-800.webp 800w, /assets/img/CompLinNonlin-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/CompLinNonlin.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Comparison of linear and nonlinear signals" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Comparison of mixing parameter behaviour for linear and nonlinear signals.</figcaption> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/AlternatingSparseNonlin-480.webp 480w, /assets/img/AlternatingSparseNonlin-800.webp 800w, /assets/img/AlternatingSparseNonlin-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/AlternatingSparseNonlin.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Alternating signals" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Signal alternating from linear to nonlinear then linear to sparse, blue line - sparse hybrid filter, red line - nonlinear hybrid filter.</figcaption> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/LinNonlinSparse-480.webp 480w, /assets/img/LinNonlinSparse-800.webp 800w, /assets/img/LinNonlinSparse-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/LinNonlinSparse.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="2D mixing parameters" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">2D representation of both filters, linear sections represented in green, nonlinear in red and sparse in blue.</figcaption> </figure> </div> </div> <hr> <h3 id="example-applications">Example Applications</h3> <h4 id="speech">Speech</h4> <ul> <li>Unvoiced Sounds <ul> <li>Most consonants are unvoiced</li> <li>Result in a noise like waveform</li> <li>Linear autoregressive models are adequate for unvoiced sounds</li> </ul> </li> <li>Voiced Sound <ul> <li>A voiced sound is one where the vocal folds are vibrating</li> <li>Periodic in nature with periodic excitation source</li> <li>All vowels and certain consonants are voiced speech</li> <li>Voiced sounds require a nonlinear model</li> </ul> </li> <li>Nasals <ul> <li>Nasals are sounds like \n\or \m\</li> <li>For nasals or certain vowels a chaotic model is appropriate</li> </ul> </li> </ul> <p>Comparing results for hybrid filters for nonlinear and sparse shows a high degree of correlation.</p> <p>\s\ sounds are more linear in nature and voiced sounds are indicated by the regions where \(\lambda\)exhibits a spiky behaviour <a class="citation" href="#Vayanos2007">[1]</a>.</p> <div class="row justify-content-center"> <div class="col-sm-6 mb-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/Speech-480.webp 480w, /assets/img/Speech-800.webp 800w, /assets/img/Speech-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/Speech.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Example speech signal" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Example speech signal. Middle: Mixing parameter for nonlinear hybrid filter. Bottom: Mixing parameter for sparse hybrid filter.</figcaption> </figure> </div> </div> <h4 id="eeg---epilepsy">EEG - Epilepsy</h4> <p>Epileptic signals fundamentally change the nature of brain activity. Using hybrid filters for both nonlinearity and sparsity we can build a feature map of the epileptic signal <a class="citation" href="#Jelfs2010">[2], [3]</a>.</p> <div class="row justify-content-center"> <div class="col-sm-8 mb-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/EEGEpilepsy-480.webp 480w, /assets/img/EEGEpilepsy-800.webp 800w, /assets/img/EEGEpilepsy-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/EEGEpilepsy.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Example epilepsy signals" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Top: Two example EEG signals showing the onset of epileptic seizures. Middle: Mixing parameters for nonlinear and sparse hybrid filters. Bottom: Feature maps for the combination of the two hybrid filters.</figcaption> </figure> </div> </div> <h4 id="eeg---consciousness-states">EEG - Consciousness States</h4> <p>Identification of brain consciousness states is a important area of EEG analysis. There are obvious legal implications to declaring a patient brain dead. Normally this assessment requires several invasive medical procedures.</p> <p>A trail test has been performed on EEG data for 34 patients, 17 in a coma and 17 considered to be brain dead. The recordings were taken in the intensive care unit of a hospital leading to high levels of noise generated by other monitoring machines.</p> <p>Nonlinearity showed clear differences but sparsity was less obvious, combining the two to produce a feature map gave a clear difference <a class="citation" href="#Li2012">[4]</a>.</p> <div class="row align-items-center"> <div class="col-sm-4 mb-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/EEGNonlinear-480.webp 480w, /assets/img/EEGNonlinear-800.webp 800w, /assets/img/EEGNonlinear-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/EEGNonlinear.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="EEG nonlinear hybrid filter" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Average performance of the nonlinear hybrid filter for the coma and quasi-brain dead patients.</figcaption> </figure> </div> <div class="col-sm-4 mb-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/EEGSparse-480.webp 480w, /assets/img/EEGSparse-800.webp 800w, /assets/img/EEGSparse-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/EEGSparse.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="EEG sparse hybrid filter" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Average performance of the sparse hybrid filter for the same patients.</figcaption> </figure> </div> <div class="col-sm-4 mb-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/EEGSparseNonlin-480.webp 480w, /assets/img/EEGSparseNonlin-800.webp 800w, /assets/img/EEGSparseNonlin-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/EEGSparseNonlin.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="EEG sparse nonlinear feature map" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Feature maps for the combination of the two hybrid filters.</figcaption> </figure> </div> </div> <h4 id="wind">Wind</h4> <p>Wind vectors \(v(k)\) can be represented in the complex domain as</p> \[v(k) = |v(k)|e^{j\theta(k)} = v_E(k) + jv_N(k)\] <p>To compare the nature of the complex signals split- &amp; fully-complex subfilters were used to predict the wind data.</p> <p>Looking at the wind data from an urban area over the course of 24 hours, the wind can be considered more fully-complex in nature. The first &amp; last samples are more unstable in nature, these areas indicate from 2pm until 6pm and from 8am until 2pm. During these periods the wind would fluctuate more than during the calm period late at night &amp; early in the morning <a class="citation" href="#Jelfs2010">[2], [5]</a></p> <div class="row align-items-center justify-content-center"> <div class="col-sm-4 mb-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/WindPolar-480.webp 480w, /assets/img/WindPolar-800.webp 800w, /assets/img/WindPolar-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/WindPolar.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Polar representation of wind" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Polar wind Profile.</figcaption> </figure> </div> <div class="col-sm-7 mb-3 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/Wind-480.webp 480w, /assets/img/Wind-800.webp 800w, /assets/img/Wind-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/Wind.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Complex wind representation" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Top: Real and imaginary parts of a wind vector. Bottom: mixing parameter for split- and fully-complex hybrid filter.</figcaption> </figure> </div> </div> <h4 id="radar">Radar</h4> <p>Radar can be represented in the complex domain and has been shown to be fully complex when the target is in the beam.</p> <p>Alternating high (turbulent) sea state and low (calm) sea state we can see that the high sea state was predominantly fully-complex and the low sea state split complex <a class="citation" href="#Jelfs2008">[3]</a>.</p> <div class="row justify-content-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/Radar-480.webp 480w, /assets/img/Radar-800.webp 800w, /assets/img/Radar-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/Radar.png" class="img-fluid rounded z-depth-1 p-2" width="100%" height="auto" alt="" title="Example radar signals" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Mixing parameter for split vs fully complex hybrid filter with radar signal alternating between turbulent and calm sea states.</figcaption> </figure> </div> </div> <hr> <h3 id="code">Code</h3> <p>Hybrid filter code can be found here: <a href="https://github.com/beteje/hybrid-filters" target="_blank" rel="noopener">hybrid-filters</a> <br> This code contains several example filters and benchmark signals and can be customised to include any adaptive filter of your choosing.</p> <hr> <h3 id="references">References</h3> <div class="references"> <ol class="bibliography"> <li> <div class="row"> <div id="Vayanos2007" class="col-sm-12"> <div class="title">Exploiting Nonlinearity in Adaptive Signal Processing</div> <div class="author"> P. Vayanos, M. Chen, <em>B. Jelfs</em>, and D. P. Mandic </div> <div class="periodical"> In <em>Advances in Nonlinear Speech Processing</em>, M. Chetouani et al. (eds), Springer Berlin Heidelberg, 2007, pp. 57â77. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0 mr-0" role="button">abstract</a> <a href="http://doi.org/10.1007/978-3-540-77347-4_3" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">doi</a> <a href="/assets/pdf/2007_NOLISP.pdf" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank">pdf</a> <a href="https://github.com/beteje/hybrid-filters" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">code</a> </div> <div class="abstract hidden"> <p>Quantitative performance criteria for the analysis of machine learning architectures and algorithms have been long established. However, the qualitative performance criteria, e.g., nonlinearity assessment, are still emerging. To that end, we employ some recent developments in signal characterisation and derive criteria for the assessment of the changes in the nature of the processed signal. In addition, we also propose a novel online method for tracking the system nonlinearity. A comprehensive set of simulations in both the linear and nonlinear settings and their combination supports the analysis.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="Jelfs2010" class="col-sm-12"> <div class="title">Characterisation of Signal Modality: Exploiting Signal Nonlinearity in Machine Learning and Signal Processing</div> <div class="author"> <em>B. Jelfs</em>, S. Javidi, P. Vayanos, and D. Mandic </div> <div class="periodical"> <em>Journal of Signal Processing Systems,</em> 2010, vol. 61, no. 1, pp. 105â115. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0 mr-0" role="button">abstract</a> <a href="http://doi.org/10.1007/s11265-009-0358-z" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">doi</a> <a href="/assets/pdf/2010_JSPS_MLSP.pdf" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank">pdf</a> <a href="https://github.com/beteje/hybrid-filters" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">code</a> </div> <div class="abstract hidden"> <p>A novel method for online tracking of the changes in the nonlinearity within both real-domain and complex-valued signals is introduced. This is achieved by a collaborative adaptive signal processing approach based on a hybrid filter. By tracking the dynamics of the adaptive mixing parameter within the employed hybrid filtering architecture, we show that it is possible to quantify the degree of nonlinearity within both real- and complex-valued data. Implementations for tracking nonlinearity in general and then more specifically sparsity are illustrated on both benchmark and real world data. It is also shown that by combining the information obtained from hybrid filters of different natures it is possible to use this method to gain a more complete understanding of the nature of the nonlinearity within a signal. This also paves the way for building multidimensional feature spaces and their application in data/information fusion.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="Jelfs2008" class="col-sm-12"> <div class="title">Collaborative Adaptive Filters for Online Knowledge Extraction and Information Fusion</div> <div class="author"> <em>B. Jelfs</em>, P. Vayanos, S. Javidi, V. S. L. Goh, and D. Mandic </div> <div class="periodical"> In <em>Signal Processing Techniques for Knowledge Extraction and Information Fusion</em>, D. Mandic et al. (eds), Springer, 2008, vol. 61, no. 1, pp. 3â21. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0 mr-0" role="button">abstract</a> <a href="http://doi.org/10.1007/978-0-387-74367-7_1" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">doi</a> <a href="/assets/pdf/2008_Knowledge_Extraction_Ch1.pdf" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank">pdf</a> <a href="https://github.com/beteje/hybrid-filters" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">code</a> </div> <div class="abstract hidden"> <p>We present a method for extracting information (or knowledge) about the nature of a signal. This is achieved by employing recent developments in signal characterisation for online analysis of the changes in signal modality. We show that it is possible to use the fusion of the outputs of adaptive filters to produce a single collaborative hybrid filter and that by tracking the dynamics of the mixing parameter of this filter rather than the actual filter performance, a clear indication as to the nature of the signal is given. Implementations of the proposed hybrid filter in both the real R and the complex C domains are analysed and the potential of such a scheme for tracking signal nonlinearity in both domains is highlighted. Simulations on linear and nonlinear signals in a prediction configuration support the analysis; real world applications of the approach have been illustrated on electroencephalogram (EEG), radar and wind data.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="Li2012" class="col-sm-12"> <div class="title">Modelling of Brain Consciousness Based on Collaborative Adaptive Filters</div> <div class="author"> L. Li, Y. Xia, <em>B. Jelfs</em>, J. Cao, and D. P. Mandic </div> <div class="periodical"> <em>Neurocomputing,</em> 2012, vol. 76, no. 1, pp. 36â43. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0 mr-0" role="button">abstract</a> <a href="http://doi.org/10.1016/j.neucom.2011.05.038" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">doi</a> <a href="/assets/pdf/2012_Neurocomputing.pdf" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank">pdf</a> <a href="https://github.com/beteje/hybrid-filters" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">code</a> </div> <div class="abstract hidden"> <p>A novel method for the discrimination between discrete states of brain consciousness is proposed, achieved through examination of nonlinear features within the electroencephalogram (EEG). To allow for real time modes of operation, a collaborative adaptive filtering architecture, using a convex combination of adaptive filters is implemented. The evolution of the mixing parameter within this structure is then used as an indication of the predominant nature of the EEG recordings. Simulations based upon a number of different filter combinations illustrate the suitability of this approach to differentiate between the coma and quasi-brain-death states based upon fundamental signal characteristics.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="Jelfs2012a" class="col-sm-12"> <div class="title">An Adaptive Approach for the Identification of Improper Complex Signals</div> <div class="author"> <em>B. Jelfs</em>, D. P. Mandic, and S. C. Douglas </div> <div class="periodical"> <em>Signal Processing,</em> 2012, vol. 92, no. 2, pp. 335â344. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0 mr-0" role="button">abstract</a> <a href="http://doi.org/10.1016/j.sigpro.2011.07.020" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">doi</a> <a href="/assets/pdf/2012_SigProc.pdf" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank">pdf</a> <a href="https://github.com/beteje/hybrid-filters" class="btn btn-sm z-depth-0 mr-0" role="button" target="_blank" rel="noopener">code</a> </div> <div class="abstract hidden"> <p>A real-time approach for the identification of second-order noncircularity (improperness) of complex valued signals is introduced. This is achieved based on a convex combination of a standard and widely linear complex adaptive filter, trained by the corresponding complex least mean square (CLMS) and augmented CLMS (ACLMS) algorithms. By providing a rigorous account of widely linear autoregressive modelling the analysis shows that the monitoring of the evolution of the adaptive convex mixing parameter within this structure makes it possible to both detect and track the complex improperness in real time, unlike current methods which are block based and static. The existence and uniqueness of the solution are illustrated through the analysis of the convergence of the convex mixing parameter. The analysis is supported by simulations on representative datasets, for a range of both proper and improper inputs.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2024 Beth Jelfs. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?c15227096669a5b10a9e60f3f87cd6a9"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>